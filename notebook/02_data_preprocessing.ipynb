{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:45:56.968743Z",
     "iopub.status.busy": "2026-02-22T09:45:56.968642Z",
     "iopub.status.idle": "2026-02-22T09:45:58.163088Z",
     "shell.execute_reply": "2026-02-22T09:45:58.162840Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Download NLTK Resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:45:58.164692Z",
     "iopub.status.busy": "2026-02-22T09:45:58.164569Z",
     "iopub.status.idle": "2026-02-22T09:45:58.442275Z",
     "shell.execute_reply": "2026-02-22T09:45:58.442031Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/magnus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/magnus/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/magnus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:45:58.457889Z",
     "iopub.status.busy": "2026-02-22T09:45:58.457778Z",
     "iopub.status.idle": "2026-02-22T09:46:00.106366Z",
     "shell.execute_reply": "2026-02-22T09:46:00.106121Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/raw/WELFake_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Remove Unnecessary Index Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:00.107864Z",
     "iopub.status.busy": "2026-02-22T09:46:00.107778Z",
     "iopub.status.idle": "2026-02-22T09:46:00.111359Z",
     "shell.execute_reply": "2026-02-22T09:46:00.111151Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Handle Missing Values in Text Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:00.112649Z",
     "iopub.status.busy": "2026-02-22T09:46:00.112570Z",
     "iopub.status.idle": "2026-02-22T09:46:00.123154Z",
     "shell.execute_reply": "2026-02-22T09:46:00.122861Z"
    }
   },
   "outputs": [],
   "source": [
    "df['title'] = df['title'].fillna('')\n",
    "df['text'] = df['text'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Combine Title and Text into Single Content Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:00.124666Z",
     "iopub.status.busy": "2026-02-22T09:46:00.124585Z",
     "iopub.status.idle": "2026-02-22T09:46:00.131296Z",
     "shell.execute_reply": "2026-02-22T09:46:00.131090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        No comment is expected from Barack Obama Membe...\n",
       "1           Did they post their votes for Hillary already?\n",
       "2         Now, most of the demonstrators gathered last ...\n",
       "3        A dozen politically active pastors came here f...\n",
       "4        The RS-28 Sarmat missile, dubbed Satan 2, will...\n",
       "                               ...                        \n",
       "72129    WASHINGTON (Reuters) - Hackers believed to be ...\n",
       "72130    You know, because in fantasyland Republicans n...\n",
       "72131    Migrants Refuse To Leave Train At Refugee Camp...\n",
       "72132    MEXICO CITY (Reuters) - Donald Trumpâ€™s combati...\n",
       "72133    Goldman Sachs Endorses Hillary Clinton For Pre...\n",
       "Name: content, Length: 72134, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use text-only (no title) to match what the backend receives at inference\n",
    "df['content'] = df['text'].fillna('')\n",
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Convert Text to Lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:00.132460Z",
     "iopub.status.busy": "2026-02-22T09:46:00.132395Z",
     "iopub.status.idle": "2026-02-22T09:46:00.539589Z",
     "shell.execute_reply": "2026-02-22T09:46:00.539327Z"
    }
   },
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Remove Punctuation and Special Characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:00.540824Z",
     "iopub.status.busy": "2026-02-22T09:46:00.540752Z",
     "iopub.status.idle": "2026-02-22T09:46:02.417008Z",
     "shell.execute_reply": "2026-02-22T09:46:02.416703Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['content'] = df['content'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Remove Extra White Spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:02.418656Z",
     "iopub.status.busy": "2026-02-22T09:46:02.418556Z",
     "iopub.status.idle": "2026-02-22T09:46:06.769407Z",
     "shell.execute_reply": "2026-02-22T09:46:06.769100Z"
    }
   },
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Load Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:06.770907Z",
     "iopub.status.busy": "2026-02-22T09:46:06.770835Z",
     "iopub.status.idle": "2026-02-22T09:46:06.774272Z",
     "shell.execute_reply": "2026-02-22T09:46:06.774013Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Remove Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:06.775579Z",
     "iopub.status.busy": "2026-02-22T09:46:06.775506Z",
     "iopub.status.idle": "2026-02-22T09:46:57.857243Z",
     "shell.execute_reply": "2026-02-22T09:46:57.856970Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df['cleaned_content'] = df['content'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:46:57.858744Z",
     "iopub.status.busy": "2026-02-22T09:46:57.858668Z",
     "iopub.status.idle": "2026-02-22T09:47:32.608909Z",
     "shell.execute_reply": "2026-02-22T09:47:32.608656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [comment, expected, barack, obama, members, fy...\n",
       "1                      [post, votes, hillary, already]\n",
       "2    [demonstrators, gathered, last, night, exercis...\n",
       "3    [dozen, politically, active, pastors, came, pr...\n",
       "4    [rs, sarmat, missile, dubbed, satan, replace, ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['cleaned_content'].apply(word_tokenize)\n",
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **13. Comparison of Content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:47:32.610326Z",
     "iopub.status.busy": "2026-02-22T09:47:32.610249Z",
     "iopub.status.idle": "2026-02-22T09:47:32.617931Z",
     "shell.execute_reply": "2026-02-22T09:47:32.617704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no comment is expected from barack obama membe...</td>\n",
       "      <td>comment expected barack obama members fyf fuky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did they post their votes for hillary already</td>\n",
       "      <td>post votes hillary already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now most of the demonstrators gathered last ni...</td>\n",
       "      <td>demonstrators gathered last night exercising c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  no comment is expected from barack obama membe...   \n",
       "1      did they post their votes for hillary already   \n",
       "2  now most of the demonstrators gathered last ni...   \n",
       "\n",
       "                                     cleaned_content  \n",
       "0  comment expected barack obama members fyf fuky...  \n",
       "1                         post votes hillary already  \n",
       "2  demonstrators gathered last night exercising c...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['content', 'cleaned_content']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **14. Check Final Null Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:47:32.619240Z",
     "iopub.status.busy": "2026-02-22T09:47:32.619165Z",
     "iopub.status.idle": "2026-02-22T09:47:32.637740Z",
     "shell.execute_reply": "2026-02-22T09:47:32.637466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "text               0\n",
       "label              0\n",
       "content            0\n",
       "cleaned_content    0\n",
       "tokens             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **15. Save Clean Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T09:47:32.639102Z",
     "iopub.status.busy": "2026-02-22T09:47:32.639028Z",
     "iopub.status.idle": "2026-02-22T09:47:39.671764Z",
     "shell.execute_reply": "2026-02-22T09:47:39.671422Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/cleaned_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **16. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text preprocessing pipeline successfully cleaned and normalized the news articles by:\n",
    "\n",
    "*   **Normalization**: Converting text to lowercase.\n",
    "*   **Sanitization**: Removing punctuation and special characters.\n",
    "*   **Filtering**: Eliminating stopwords.\n",
    "*   **Noise Reduction**: Reducing inconsistencies in the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
